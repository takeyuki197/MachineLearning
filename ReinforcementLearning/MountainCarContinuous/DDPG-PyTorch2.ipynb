{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import gym, time\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import pandas as pd\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('MountainCarContinuous-v0')\n",
    "env.seed(1234)\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, learning_rate=0.01, state_size=2, \n",
    "                 action_size=1, hidden_size=10, batch_size=20,\n",
    "                 name='QNetwork'):\n",
    "        nn.Module.__init__(self)\n",
    "        self.fc1 = nn.Linear(state_size+action_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.output = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyNetwork(nn.Module):\n",
    "    def __init__(self, learning_rate=0.01, state_size=2, \n",
    "                 action_size=1, hidden_size=10, batch_size=20,\n",
    "                 name='PolicyNetwork'):\n",
    "        nn.Module.__init__(self)\n",
    "        self.fc1 = nn.Linear(state_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.output = nn.Linear(hidden_size, action_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.output(x)\n",
    "        x = torch.tanh(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "class Memory():\n",
    "    def __init__(self, max_size = 1000):\n",
    "        self.buffer = deque(maxlen=max_size)\n",
    "    \n",
    "    def add(self, experience):\n",
    "        self.buffer.append(experience)\n",
    "            \n",
    "    def sample(self, batch_size):\n",
    "        idx = np.random.choice(np.arange(len(self.buffer)), \n",
    "                               size=batch_size, \n",
    "                               replace=False)\n",
    "        return [self.buffer[ii] for ii in idx]\n",
    "    \n",
    "    def length(self):\n",
    "        return len(self.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_episodes = 500          # max number of episodes to learn from\n",
    "max_steps = 1000                # max steps in an episode\n",
    "gamma = 0.99                   # future reward discount\n",
    "\n",
    "action_size = 1\n",
    "\n",
    "# Exploration parameters\n",
    "explore_start = 0.2            # exploration probability at start\n",
    "explore_stop = 0.001            # minimum exploration probability \n",
    "decay_rate = 0.0001            # exponential decay rate for exploration prob\n",
    "\n",
    "# Network parameters\n",
    "hidden_size = 16               # number of units in each Q-network hidden layer\n",
    "learning_rate = 0.01         # Q-network learning rate\n",
    "\n",
    "# Memory parameters\n",
    "memory_size = 200000            # memory capacity\n",
    "batch_size = 512                # experience mini-batch size\n",
    "pretrain_length = batch_size   # number experiences to pretrain the memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = Memory(memory_size)\n",
    "q_network = QNetwork(name='main', hidden_size=hidden_size, learning_rate=learning_rate,batch_size=batch_size)\n",
    "policy_network = PolicyNetwork(name='main', hidden_size=hidden_size, learning_rate=learning_rate,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1 Total reward: -11.573387298250118 Training loss: 0.1402\n",
      "Episode: 2 Total reward: -0.7775370094618536 Training loss: -0.0061\n",
      "Episode: 3 Total reward: -0.4016750451140772 Training loss: 0.0024\n",
      "Episode: 4 Total reward: -2.2096570716977038 Training loss: 0.0078\n",
      "Episode: 5 Total reward: -0.7513376222000755 Training loss: -0.0365\n",
      "Episode: 6 Total reward: -0.5871122676107833 Training loss: 0.0452\n",
      "Episode: 7 Total reward: -0.6033711956846954 Training loss: -0.0682\n",
      "Episode: 8 Total reward: -1.0090334929458231 Training loss: 0.0240\n",
      "Episode: 9 Total reward: -1.5328173289578242 Training loss: 0.0237\n",
      "Episode: 10 Total reward: -1.6403191494752234 Training loss: 0.0634\n",
      "Episode: 11 Total reward: -1.484778437075155 Training loss: 0.0870\n",
      "Episode: 12 Total reward: -0.8729683062949485 Training loss: 0.0384\n",
      "Episode: 13 Total reward: -0.7006383950713759 Training loss: 0.0168\n",
      "Episode: 14 Total reward: -0.3310731330884581 Training loss: -0.0280\n",
      "Episode: 15 Total reward: -0.21658897785122133 Training loss: -0.0325\n",
      "Episode: 16 Total reward: -0.21251624464338403 Training loss: -0.0197\n",
      "Episode: 17 Total reward: -0.25628149139204176 Training loss: -0.0147\n",
      "Episode: 18 Total reward: -0.25207437377350234 Training loss: -0.0171\n",
      "Episode: 19 Total reward: -0.2622341807727628 Training loss: 0.0098\n",
      "Episode: 20 Total reward: -0.27142523253740286 Training loss: -0.0049\n",
      "Episode: 21 Total reward: -0.19794219116460085 Training loss: -0.0165\n",
      "Episode: 22 Total reward: -0.3423473971364951 Training loss: -0.0217\n",
      "Episode: 23 Total reward: -0.30977688677142756 Training loss: -0.0185\n",
      "Episode: 24 Total reward: -0.25465554797997486 Training loss: -0.0112\n",
      "Episode: 25 Total reward: -0.27591018429034875 Training loss: -0.0116\n",
      "Episode: 26 Total reward: -0.26897750052341163 Training loss: -0.0119\n",
      "Episode: 27 Total reward: -0.24634580907609563 Training loss: -0.0080\n",
      "Episode: 28 Total reward: -0.3015483217420791 Training loss: -0.0072\n",
      "Episode: 29 Total reward: -0.47346122238191723 Training loss: -0.0058\n",
      "Episode: 30 Total reward: -0.4563073874052217 Training loss: 0.0047\n",
      "Episode: 31 Total reward: -0.37738004236199635 Training loss: -0.0056\n",
      "Episode: 32 Total reward: -0.33747432789524734 Training loss: -0.0032\n",
      "Episode: 33 Total reward: -0.320814450040919 Training loss: 0.0013\n",
      "Episode: 34 Total reward: -0.37280439698794265 Training loss: 0.0004\n",
      "Episode: 35 Total reward: -0.3196152800011563 Training loss: -0.0009\n",
      "Episode: 36 Total reward: -0.32698871108990146 Training loss: 0.0012\n",
      "Episode: 37 Total reward: -0.32670461034262577 Training loss: 0.0072\n",
      "Episode: 38 Total reward: -0.3683265432031675 Training loss: 0.0040\n",
      "Episode: 39 Total reward: -0.3511726956260494 Training loss: 0.0050\n",
      "Episode: 40 Total reward: -0.3673555329933883 Training loss: 0.0062\n",
      "Episode: 41 Total reward: -0.3306719237056649 Training loss: 0.0029\n",
      "Episode: 42 Total reward: -0.34406906727066694 Training loss: 0.0029\n",
      "Episode: 43 Total reward: -0.32588730319720044 Training loss: 0.0024\n",
      "Episode: 44 Total reward: -0.3461885986433134 Training loss: 0.0048\n",
      "Episode: 45 Total reward: -0.31248208467631944 Training loss: 0.0039\n",
      "Episode: 46 Total reward: -0.3086686754840072 Training loss: 0.0045\n",
      "Episode: 47 Total reward: -0.28273774877083163 Training loss: 0.0031\n",
      "Episode: 48 Total reward: -0.4037637871503992 Training loss: 0.0034\n",
      "Episode: 49 Total reward: -0.2846309889428116 Training loss: 0.0059\n",
      "Episode: 50 Total reward: -0.3521410787127628 Training loss: 0.0055\n",
      "Episode: 51 Total reward: -0.2669707093646035 Training loss: 0.0042\n",
      "Episode: 52 Total reward: -0.30536296464945945 Training loss: 0.0044\n",
      "Episode: 53 Total reward: -0.2967446638000556 Training loss: 0.0064\n",
      "Episode: 54 Total reward: -0.3589927606208178 Training loss: 0.0043\n",
      "Episode: 55 Total reward: -0.3222769410053695 Training loss: 0.0033\n",
      "Episode: 56 Total reward: -0.3285087413401425 Training loss: 0.0037\n",
      "Episode: 57 Total reward: -0.3399438112693383 Training loss: 0.0029\n",
      "Episode: 58 Total reward: -0.3188969911779002 Training loss: 0.0035\n",
      "Episode: 59 Total reward: -0.2751421062457958 Training loss: 0.0035\n",
      "Episode: 60 Total reward: -0.2868850723207394 Training loss: 0.0045\n",
      "Episode: 61 Total reward: -0.3553716387503948 Training loss: 0.0033\n",
      "Episode: 62 Total reward: -0.2463733430060842 Training loss: 0.0018\n",
      "Episode: 63 Total reward: -0.3514164862087881 Training loss: 0.0084\n",
      "Episode: 64 Total reward: -0.25945620031570443 Training loss: 0.0046\n",
      "Episode: 65 Total reward: -0.277992284729932 Training loss: 0.0047\n",
      "Episode: 66 Total reward: -0.2857744088217607 Training loss: 0.0023\n",
      "Episode: 67 Total reward: -0.2326694783503116 Training loss: 0.0043\n",
      "Episode: 68 Total reward: -0.2580984161304868 Training loss: 0.0045\n",
      "Episode: 69 Total reward: -0.2414945245286699 Training loss: 0.0045\n",
      "Episode: 70 Total reward: -0.2929046584708184 Training loss: 0.0046\n",
      "Episode: 71 Total reward: -0.25360768183024407 Training loss: 0.0050\n",
      "Episode: 72 Total reward: -0.26697721748910735 Training loss: 0.0048\n",
      "Episode: 73 Total reward: -0.2854592555800876 Training loss: 0.0044\n",
      "Episode: 74 Total reward: -0.2520352815702358 Training loss: 0.0052\n",
      "Episode: 75 Total reward: -0.27111056164417224 Training loss: 0.0045\n",
      "Episode: 76 Total reward: -0.25472011816044887 Training loss: 0.0052\n",
      "Episode: 77 Total reward: -0.25021687240411716 Training loss: 0.0050\n",
      "Episode: 78 Total reward: -0.31292879855020117 Training loss: 0.0069\n",
      "Episode: 79 Total reward: -0.23697722341158833 Training loss: 0.0033\n",
      "Episode: 80 Total reward: -0.3965759634329439 Training loss: 0.0034\n",
      "Episode: 81 Total reward: -0.4134464277478459 Training loss: 0.0045\n",
      "Episode: 82 Total reward: -0.34774360164354035 Training loss: 0.0028\n",
      "Episode: 83 Total reward: -0.3930081106329815 Training loss: 0.0047\n",
      "Episode: 84 Total reward: -0.3965135980623717 Training loss: 0.0034\n",
      "Episode: 85 Total reward: -0.3803446194397423 Training loss: 0.0027\n",
      "Episode: 86 Total reward: -0.4527356756615179 Training loss: 0.0026\n",
      "Episode: 87 Total reward: -0.3680837335951041 Training loss: 0.0036\n",
      "Episode: 88 Total reward: -0.3513156008225218 Training loss: 0.0032\n",
      "Episode: 89 Total reward: -0.3995507915739737 Training loss: 0.0030\n",
      "Episode: 90 Total reward: -0.40112090550786467 Training loss: 0.0054\n",
      "Episode: 91 Total reward: -0.3593839671858007 Training loss: 0.0044\n",
      "Episode: 92 Total reward: -0.34788684373433326 Training loss: 0.0031\n",
      "Episode: 93 Total reward: -0.41178653364546447 Training loss: 0.0022\n",
      "Episode: 94 Total reward: -0.3653594901201283 Training loss: 0.0027\n",
      "Episode: 95 Total reward: -0.3201167765286488 Training loss: 0.0039\n",
      "Episode: 96 Total reward: -0.3919986637368478 Training loss: 0.0037\n",
      "Episode: 97 Total reward: -0.3142381038360745 Training loss: 0.0036\n",
      "Episode: 98 Total reward: -0.3860213274634139 Training loss: 0.0032\n",
      "Episode: 99 Total reward: -0.3666231197759218 Training loss: 0.0044\n",
      "Episode: 100 Total reward: -0.3709592744480084 Training loss: 0.0021\n",
      "Episode: 101 Total reward: -0.40527208391986835 Training loss: 0.0027\n",
      "Episode: 102 Total reward: -0.39012222328285906 Training loss: 0.0036\n",
      "Episode: 103 Total reward: -0.34289673059929304 Training loss: 0.0034\n",
      "Episode: 104 Total reward: -0.42241764988908753 Training loss: 0.0030\n",
      "Episode: 105 Total reward: -0.4258535356929861 Training loss: 0.0028\n",
      "Episode: 106 Total reward: -0.3543782327312177 Training loss: 0.0018\n",
      "Episode: 107 Total reward: -0.36105235500673055 Training loss: 0.0031\n",
      "Episode: 108 Total reward: -0.31650281537066105 Training loss: 0.0041\n",
      "Episode: 109 Total reward: -0.3795075490609562 Training loss: 0.0035\n",
      "Episode: 110 Total reward: -0.34359314113242995 Training loss: 0.0029\n",
      "Episode: 111 Total reward: -0.4186753513123591 Training loss: 0.0038\n",
      "Episode: 112 Total reward: -0.4209753487219663 Training loss: 0.0039\n",
      "Episode: 113 Total reward: -0.4035217220104482 Training loss: 0.0034\n",
      "Episode: 114 Total reward: -0.3883787683563315 Training loss: 0.0025\n",
      "Episode: 115 Total reward: -0.37018382313493076 Training loss: 0.0029\n",
      "Episode: 116 Total reward: -0.3909982480791244 Training loss: 0.0030\n",
      "Episode: 117 Total reward: -0.3756488304780118 Training loss: 0.0029\n",
      "Episode: 118 Total reward: -0.3713875352329538 Training loss: 0.0030\n",
      "Episode: 119 Total reward: -0.4035005340968344 Training loss: 0.0021\n",
      "Episode: 120 Total reward: -0.3339771466364505 Training loss: 0.0030\n",
      "Episode: 121 Total reward: -0.435018724340434 Training loss: 0.0035\n",
      "Episode: 122 Total reward: -0.4116939712219757 Training loss: 0.0038\n",
      "Episode: 123 Total reward: -0.3638918546227469 Training loss: 0.0034\n",
      "Episode: 124 Total reward: -0.3766031067370054 Training loss: 0.0025\n",
      "Episode: 125 Total reward: -0.334908848922966 Training loss: 0.0036\n",
      "Episode: 126 Total reward: -0.32798887440822466 Training loss: 0.0034\n",
      "Episode: 127 Total reward: -0.3645042832076256 Training loss: 0.0030\n",
      "Episode: 128 Total reward: -0.41244799227734275 Training loss: 0.0030\n",
      "Episode: 129 Total reward: -0.40174359839955487 Training loss: 0.0036\n",
      "Episode: 130 Total reward: -0.3764642606873042 Training loss: 0.0034\n",
      "Episode: 131 Total reward: -0.3362326282075911 Training loss: 0.0035\n",
      "Episode: 132 Total reward: -0.3805231431633138 Training loss: 0.0026\n",
      "Episode: 133 Total reward: -0.39677921137025834 Training loss: 0.0034\n",
      "Episode: 134 Total reward: -0.38223767618482096 Training loss: 0.0020\n",
      "Episode: 135 Total reward: -0.3627333790166163 Training loss: 0.0035\n",
      "Episode: 136 Total reward: -0.38522912641863233 Training loss: 0.0019\n",
      "Episode: 137 Total reward: -0.29580498752078216 Training loss: 0.0030\n",
      "Episode: 138 Total reward: -0.38805882133570857 Training loss: 0.0042\n",
      "Episode: 139 Total reward: -0.3874512537883907 Training loss: 0.0032\n",
      "Episode: 140 Total reward: -0.3738244970810197 Training loss: 0.0027\n",
      "Episode: 141 Total reward: -0.3693539246716346 Training loss: 0.0032\n",
      "Episode: 142 Total reward: -0.3486174670109571 Training loss: 0.0020\n",
      "Episode: 143 Total reward: -0.3577148365720661 Training loss: 0.0031\n",
      "Episode: 144 Total reward: -0.39249602798705857 Training loss: 0.0035\n",
      "Episode: 145 Total reward: -0.3713810060659607 Training loss: 0.0019\n",
      "Episode: 146 Total reward: -0.37120080610869555 Training loss: 0.0032\n",
      "Episode: 147 Total reward: -0.3440871438260691 Training loss: 0.0039\n",
      "Episode: 148 Total reward: -0.3394102033555913 Training loss: 0.0031\n",
      "Episode: 149 Total reward: -0.4025645194431982 Training loss: 0.0028\n",
      "Episode: 150 Total reward: -0.4031043149655709 Training loss: 0.0033\n",
      "Episode: 151 Total reward: -0.4320947417055847 Training loss: 0.0026\n",
      "Episode: 152 Total reward: -0.30270990485325316 Training loss: 0.0046\n",
      "Episode: 153 Total reward: -0.35513125719424227 Training loss: 0.0037\n",
      "Episode: 154 Total reward: -0.3910110794077654 Training loss: 0.0033\n",
      "Episode: 155 Total reward: -0.411693520911833 Training loss: 0.0020\n",
      "Episode: 156 Total reward: -0.35167899235218886 Training loss: 0.0030\n",
      "Episode: 157 Total reward: -0.38786465744682275 Training loss: 0.0025\n",
      "Episode: 158 Total reward: -0.3711429773466013 Training loss: 0.0027\n",
      "Episode: 159 Total reward: -0.3840452094213309 Training loss: 0.0037\n",
      "Episode: 160 Total reward: -0.37836497629452837 Training loss: 0.0037\n",
      "Episode: 161 Total reward: -0.32998864416000184 Training loss: 0.0035\n",
      "Episode: 162 Total reward: -0.3722576408394852 Training loss: 0.0032\n",
      "Episode: 163 Total reward: -0.39455121799071413 Training loss: 0.0030\n",
      "Episode: 164 Total reward: -0.3684974325095932 Training loss: 0.0036\n",
      "Episode: 165 Total reward: -0.3912990107917762 Training loss: 0.0035\n",
      "Episode: 166 Total reward: -0.38762662971675177 Training loss: 0.0035\n",
      "Episode: 167 Total reward: -0.3942478915294376 Training loss: 0.0036\n",
      "Episode: 168 Total reward: -0.37258951445679567 Training loss: 0.0037\n",
      "Episode: 169 Total reward: -0.4520095137643232 Training loss: 0.0034\n",
      "Episode: 170 Total reward: -0.40141243395869486 Training loss: 0.0031\n",
      "Episode: 171 Total reward: -0.45860596233019507 Training loss: 0.0031\n",
      "Episode: 172 Total reward: -0.3755854876015735 Training loss: 0.0032\n",
      "Episode: 173 Total reward: -0.38991794052869927 Training loss: 0.0039\n",
      "Episode: 174 Total reward: -0.33762985155972913 Training loss: 0.0076\n",
      "Episode: 175 Total reward: -0.4191880482462856 Training loss: 0.0013\n",
      "Episode: 176 Total reward: -0.40454689878561356 Training loss: 0.0034\n",
      "Episode: 177 Total reward: -0.37201231905401283 Training loss: 0.0052\n",
      "Episode: 178 Total reward: -0.35506193189204627 Training loss: 0.0039\n",
      "Episode: 179 Total reward: -0.41017169592748043 Training loss: 0.0030\n",
      "Episode: 180 Total reward: -0.40452301706561433 Training loss: 0.0030\n",
      "Episode: 181 Total reward: -0.37063873610775644 Training loss: 0.0035\n",
      "Episode: 182 Total reward: -0.436091372558468 Training loss: 0.0040\n",
      "Episode: 183 Total reward: -0.41379839489667863 Training loss: 0.0030\n",
      "Episode: 184 Total reward: -0.43036720803234946 Training loss: 0.0036\n",
      "Episode: 185 Total reward: -0.3771715941747663 Training loss: 0.0025\n",
      "Episode: 186 Total reward: -0.43826644388067687 Training loss: 0.0034\n",
      "Episode: 187 Total reward: -0.373058854306293 Training loss: 0.0022\n",
      "Episode: 188 Total reward: -0.39673184135170103 Training loss: 0.0026\n",
      "Episode: 189 Total reward: -0.3521219857888194 Training loss: 0.0026\n",
      "Episode: 190 Total reward: -0.3563272409844815 Training loss: 0.0033\n",
      "Episode: 191 Total reward: -0.32146733927752386 Training loss: 0.0029\n",
      "Episode: 192 Total reward: -0.38874373658839884 Training loss: 0.0030\n",
      "Episode: 193 Total reward: -0.4332065465632434 Training loss: 0.0037\n",
      "Episode: 194 Total reward: -0.379156757516586 Training loss: 0.0025\n",
      "Episode: 195 Total reward: -0.379488137255936 Training loss: 0.0037\n",
      "Episode: 196 Total reward: -0.3513944778834386 Training loss: 0.0021\n",
      "Episode: 197 Total reward: -0.40495421723435054 Training loss: 0.0031\n",
      "Episode: 198 Total reward: -0.3533264426421708 Training loss: 0.0038\n",
      "Episode: 199 Total reward: -0.37733320292333816 Training loss: 0.0039\n",
      "Episode: 200 Total reward: -0.42581638625887663 Training loss: 0.0019\n",
      "Episode: 201 Total reward: -0.3811150425048792 Training loss: 0.0034\n",
      "Episode: 202 Total reward: -0.4031771863438742 Training loss: 0.0038\n",
      "Episode: 203 Total reward: -0.3446127363480098 Training loss: 0.0035\n",
      "Episode: 204 Total reward: -0.22795387611806103 Training loss: 0.0028\n",
      "Episode: 205 Total reward: -0.2388342963852652 Training loss: 0.0031\n",
      "Episode: 206 Total reward: -0.22144807257050883 Training loss: 0.0022\n",
      "Episode: 207 Total reward: -0.17872836700094208 Training loss: 0.0031\n",
      "Episode: 208 Total reward: -0.2391994266267146 Training loss: 0.0030\n",
      "Episode: 209 Total reward: -0.24728825365253643 Training loss: 0.0042\n",
      "Episode: 210 Total reward: -0.24465867898428595 Training loss: 0.0031\n",
      "Episode: 211 Total reward: -0.3732313673550993 Training loss: 0.0023\n",
      "Episode: 212 Total reward: -0.32736213369674727 Training loss: 0.0024\n",
      "Episode: 213 Total reward: -0.33842109744981463 Training loss: 0.0026\n",
      "Episode: 214 Total reward: -0.3664510488908951 Training loss: 0.0028\n",
      "Episode: 215 Total reward: -0.33389843913093836 Training loss: 0.0012\n",
      "Episode: 216 Total reward: -0.3487764204389694 Training loss: 0.0016\n",
      "Episode: 217 Total reward: -0.32786818742407614 Training loss: 0.0012\n",
      "Episode: 218 Total reward: -0.3308241067039404 Training loss: 0.0011\n",
      "Episode: 219 Total reward: -0.284195730232141 Training loss: 0.0009\n",
      "Episode: 220 Total reward: -0.31423058908600554 Training loss: 0.0010\n",
      "Episode: 221 Total reward: -0.2866762914450201 Training loss: 0.0008\n",
      "Episode: 222 Total reward: -0.3160345183103111 Training loss: 0.0003\n",
      "Episode: 223 Total reward: -0.2978662936941667 Training loss: 0.0010\n",
      "Episode: 224 Total reward: -0.3349853510291883 Training loss: 0.0012\n",
      "Episode: 225 Total reward: -0.3530774336384429 Training loss: 0.0012\n",
      "Episode: 226 Total reward: -0.31334590672113094 Training loss: 0.0007\n",
      "Episode: 227 Total reward: -0.38143176345298946 Training loss: 0.0009\n",
      "Episode: 228 Total reward: -0.3108801243026725 Training loss: 0.0011\n",
      "Episode: 229 Total reward: -0.3625086640692939 Training loss: 0.0012\n",
      "Episode: 230 Total reward: -0.33544779859770446 Training loss: 0.0009\n",
      "Episode: 231 Total reward: -0.28792753277251426 Training loss: 0.0008\n",
      "Episode: 232 Total reward: -0.29253660413757276 Training loss: 0.0014\n",
      "Episode: 233 Total reward: -0.34872680614491647 Training loss: 0.0008\n",
      "Episode: 234 Total reward: -0.31320834360449795 Training loss: 0.0011\n",
      "Episode: 235 Total reward: -0.320002332688834 Training loss: 0.0008\n",
      "Episode: 236 Total reward: -0.3505903184828068 Training loss: 0.0013\n",
      "Episode: 237 Total reward: -0.3971425794065976 Training loss: 0.0007\n",
      "Episode: 238 Total reward: -0.36843545953067486 Training loss: 0.0010\n",
      "Episode: 239 Total reward: -0.3160337981265191 Training loss: 0.0011\n",
      "Episode: 240 Total reward: -0.31940643657689677 Training loss: 0.0010\n",
      "Episode: 241 Total reward: -0.3201027450446013 Training loss: 0.0015\n",
      "Episode: 242 Total reward: -0.3301554973764289 Training loss: 0.0012\n",
      "Episode: 243 Total reward: -0.3073193898763065 Training loss: 0.0016\n",
      "Episode: 244 Total reward: -0.32889980838726585 Training loss: 0.0010\n",
      "Episode: 245 Total reward: -0.34764332098429696 Training loss: 0.0009\n",
      "Episode: 246 Total reward: -0.2989030295641236 Training loss: 0.0008\n",
      "Episode: 247 Total reward: -0.3288930376020959 Training loss: 0.0015\n",
      "Episode: 248 Total reward: -0.3081225118182367 Training loss: 0.0014\n",
      "Episode: 249 Total reward: -0.3196539557494405 Training loss: 0.0013\n",
      "Episode: 250 Total reward: -0.3092065543714358 Training loss: 0.0011\n",
      "Episode: 251 Total reward: -0.2703687134455294 Training loss: 0.0009\n",
      "Episode: 252 Total reward: -0.34879831465386046 Training loss: 0.0009\n",
      "Episode: 253 Total reward: -0.33411777091756106 Training loss: 0.0012\n",
      "Episode: 254 Total reward: -0.3180911391227416 Training loss: 0.0013\n",
      "Episode: 255 Total reward: -0.3007638049365447 Training loss: 0.0016\n",
      "Episode: 256 Total reward: -0.37360857202947995 Training loss: 0.0014\n",
      "Episode: 257 Total reward: -0.31316113291493536 Training loss: 0.0012\n",
      "Episode: 258 Total reward: -0.3461365842052359 Training loss: 0.0011\n",
      "Episode: 259 Total reward: -0.3107773060132457 Training loss: 0.0008\n",
      "Episode: 260 Total reward: -0.39631186376204575 Training loss: 0.0013\n",
      "Episode: 261 Total reward: -0.39582793829898705 Training loss: 0.0010\n",
      "Episode: 262 Total reward: -0.31968569411627523 Training loss: 0.0018\n",
      "Episode: 263 Total reward: -0.3792699883251974 Training loss: 0.0017\n",
      "Episode: 264 Total reward: -0.3463113386530738 Training loss: 0.0014\n",
      "Episode: 265 Total reward: -0.38114516012312305 Training loss: 0.0018\n",
      "Episode: 266 Total reward: -0.3273938576825041 Training loss: 0.0012\n",
      "Episode: 267 Total reward: -0.3140809703222909 Training loss: 0.0013\n",
      "Episode: 268 Total reward: -0.29381537049383655 Training loss: 0.0013\n",
      "Episode: 269 Total reward: -0.30940550010787693 Training loss: 0.0015\n",
      "Episode: 270 Total reward: -0.3432390508037149 Training loss: 0.0013\n",
      "Episode: 271 Total reward: -0.33660626712629604 Training loss: 0.0012\n",
      "Episode: 272 Total reward: -0.3390255472688935 Training loss: 0.0014\n",
      "Episode: 273 Total reward: -0.3376669308902084 Training loss: 0.0014\n",
      "Episode: 274 Total reward: -0.3369146150457758 Training loss: 0.0011\n",
      "Episode: 275 Total reward: -0.32710276947781475 Training loss: 0.0012\n",
      "Episode: 276 Total reward: -0.30373145987050204 Training loss: 0.0013\n",
      "Episode: 277 Total reward: -0.30592782568386123 Training loss: 0.0014\n",
      "Episode: 278 Total reward: -0.3561521488640793 Training loss: 0.0014\n",
      "Episode: 279 Total reward: -0.3425406083206191 Training loss: 0.0015\n",
      "Episode: 280 Total reward: -0.26499124884410813 Training loss: 0.0013\n",
      "Episode: 281 Total reward: -0.3687455443931944 Training loss: 0.0014\n",
      "Episode: 282 Total reward: -0.3231437015017012 Training loss: 0.0015\n",
      "Episode: 283 Total reward: -0.29271832335926784 Training loss: 0.0016\n",
      "Episode: 284 Total reward: -0.2883421633473761 Training loss: 0.0017\n",
      "Episode: 285 Total reward: -0.38503209157044954 Training loss: 0.0012\n",
      "Episode: 286 Total reward: -0.2796985899770055 Training loss: 0.0015\n",
      "Episode: 287 Total reward: -0.3290770814032638 Training loss: 0.0013\n",
      "Episode: 288 Total reward: -0.3620604957943298 Training loss: 0.0013\n",
      "Episode: 289 Total reward: -0.3242374403854115 Training loss: 0.0015\n",
      "Episode: 290 Total reward: -0.3718797403300008 Training loss: 0.0016\n",
      "Episode: 291 Total reward: -0.30622386566364335 Training loss: 0.0012\n",
      "Episode: 292 Total reward: -0.3492241021942031 Training loss: 0.0013\n",
      "Episode: 293 Total reward: -0.29303647410868533 Training loss: 0.0014\n",
      "Episode: 294 Total reward: -0.2901047419781178 Training loss: 0.0014\n",
      "Episode: 295 Total reward: -0.38291430923090525 Training loss: 0.0015\n",
      "Episode: 296 Total reward: -0.32239915756287624 Training loss: 0.0012\n",
      "Episode: 297 Total reward: -0.31294478482312477 Training loss: 0.0014\n",
      "Episode: 298 Total reward: -0.3920884398024631 Training loss: 0.0018\n",
      "Episode: 299 Total reward: -0.3372895523234019 Training loss: 0.0010\n",
      "Episode: 300 Total reward: -0.3187516755265418 Training loss: 0.0016\n",
      "Episode: 301 Total reward: -0.33300199052521795 Training loss: 0.0013\n",
      "Episode: 302 Total reward: -0.3174627108203477 Training loss: 0.0022\n",
      "Episode: 303 Total reward: -0.2744363619424375 Training loss: 0.0026\n",
      "Episode: 304 Total reward: -0.25947591789916696 Training loss: 0.0019\n",
      "Episode: 305 Total reward: -0.28232740868039685 Training loss: 0.0018\n",
      "Episode: 306 Total reward: -0.267444859286883 Training loss: 0.0016\n",
      "Episode: 307 Total reward: -0.2582232651474431 Training loss: 0.0023\n",
      "Episode: 308 Total reward: -0.26599906030529163 Training loss: 0.0016\n",
      "Episode: 309 Total reward: -0.25062368066119484 Training loss: 0.0014\n",
      "Episode: 310 Total reward: -0.28307453135267524 Training loss: 0.0020\n",
      "Episode: 311 Total reward: -0.26348084796931814 Training loss: 0.0022\n",
      "Episode: 312 Total reward: -0.2644138249770188 Training loss: 0.0021\n",
      "Episode: 313 Total reward: -0.2075762371665554 Training loss: 0.0025\n",
      "Episode: 314 Total reward: -0.25790497967262527 Training loss: 0.0021\n",
      "Episode: 315 Total reward: -0.23807787801054692 Training loss: 0.0017\n",
      "Episode: 316 Total reward: -0.25296501300895946 Training loss: 0.0020\n",
      "Episode: 317 Total reward: -0.2946321624734826 Training loss: 0.0023\n",
      "Episode: 318 Total reward: -0.2510286814950405 Training loss: 0.0018\n",
      "Episode: 319 Total reward: -0.23233377674616265 Training loss: 0.0020\n",
      "Episode: 320 Total reward: -0.2816262140235418 Training loss: 0.0022\n",
      "Episode: 321 Total reward: -0.20900655123758952 Training loss: 0.0021\n",
      "Episode: 322 Total reward: -0.26220512148532626 Training loss: 0.0016\n",
      "Episode: 323 Total reward: -0.2654912598907684 Training loss: 0.0018\n",
      "Episode: 324 Total reward: -0.2820866139880756 Training loss: 0.0021\n",
      "Episode: 325 Total reward: -0.2902587881575166 Training loss: 0.0015\n",
      "Episode: 326 Total reward: -0.23003398165240083 Training loss: 0.0011\n",
      "Episode: 327 Total reward: -0.271342686463754 Training loss: 0.0021\n",
      "Episode: 328 Total reward: -0.22362608860001784 Training loss: 0.0016\n",
      "Episode: 329 Total reward: -0.242503863468972 Training loss: 0.0017\n",
      "Episode: 330 Total reward: -0.27356628961637247 Training loss: 0.0022\n",
      "Episode: 331 Total reward: -0.24819447541754006 Training loss: 0.0024\n",
      "Episode: 332 Total reward: -0.26403623587070774 Training loss: 0.0016\n",
      "Episode: 333 Total reward: -0.25550345551009257 Training loss: 0.0019\n",
      "Episode: 334 Total reward: -0.24152894492651233 Training loss: 0.0014\n",
      "Episode: 335 Total reward: -0.24492977186240245 Training loss: 0.0021\n",
      "Episode: 336 Total reward: -0.28339219053633025 Training loss: 0.0015\n",
      "Episode: 337 Total reward: -0.2676322820532962 Training loss: 0.0020\n",
      "Episode: 338 Total reward: -0.2652289024601925 Training loss: 0.0017\n",
      "Episode: 339 Total reward: -0.2280654666003516 Training loss: 0.0017\n",
      "Episode: 340 Total reward: -0.2592854365046378 Training loss: 0.0018\n",
      "Episode: 341 Total reward: -0.2633600549010337 Training loss: 0.0023\n",
      "Episode: 342 Total reward: -0.2937053658329772 Training loss: 0.0021\n",
      "Episode: 343 Total reward: -0.23966807237779902 Training loss: 0.0017\n",
      "Episode: 344 Total reward: -0.2560418292456419 Training loss: 0.0015\n",
      "Episode: 345 Total reward: -0.24443109708455912 Training loss: 0.0018\n",
      "Episode: 346 Total reward: -0.2640169642818334 Training loss: 0.0013\n",
      "Episode: 347 Total reward: -0.26964209776641285 Training loss: 0.0014\n",
      "Episode: 348 Total reward: -0.27117425459905337 Training loss: 0.0014\n",
      "Episode: 349 Total reward: -0.18822269529139213 Training loss: 0.0010\n",
      "Episode: 350 Total reward: -0.2514409923363356 Training loss: 0.0018\n",
      "Episode: 351 Total reward: -0.23540298487085093 Training loss: 0.0012\n",
      "Episode: 352 Total reward: -0.2590081014472212 Training loss: 0.0012\n",
      "Episode: 353 Total reward: -0.24432207096298716 Training loss: 0.0018\n",
      "Episode: 354 Total reward: -0.21943174687732236 Training loss: 0.0013\n",
      "Episode: 355 Total reward: -0.265905572396285 Training loss: 0.0017\n",
      "Episode: 356 Total reward: -0.22547666744411465 Training loss: 0.0010\n",
      "Episode: 357 Total reward: -0.27353637115162516 Training loss: 0.0018\n",
      "Episode: 358 Total reward: -0.20745747329448766 Training loss: 0.0016\n",
      "Episode: 359 Total reward: -0.27378245548064145 Training loss: 0.0017\n",
      "Episode: 360 Total reward: -0.2583366786790877 Training loss: 0.0008\n",
      "Episode: 361 Total reward: -0.2691310876973185 Training loss: 0.0013\n",
      "Episode: 362 Total reward: -0.2604862049270412 Training loss: 0.0009\n",
      "Episode: 363 Total reward: -0.2514301228715451 Training loss: 0.0016\n",
      "Episode: 364 Total reward: -0.22965304896863448 Training loss: 0.0014\n",
      "Episode: 365 Total reward: -0.24210218705987846 Training loss: 0.0013\n",
      "Episode: 366 Total reward: -0.26509640918462424 Training loss: 0.0014\n",
      "Episode: 367 Total reward: -0.20674481389103644 Training loss: 0.0009\n",
      "Episode: 368 Total reward: -0.2433003596263255 Training loss: 0.0016\n",
      "Episode: 369 Total reward: -0.25879793027365383 Training loss: 0.0016\n",
      "Episode: 370 Total reward: -0.2412770866176962 Training loss: 0.0013\n",
      "Episode: 371 Total reward: -0.28761749406279624 Training loss: 0.0012\n",
      "Episode: 372 Total reward: -0.21839459181359036 Training loss: 0.0013\n",
      "Episode: 373 Total reward: -0.24602589048121215 Training loss: 0.0011\n",
      "Episode: 374 Total reward: -0.27935476663133396 Training loss: 0.0010\n",
      "Episode: 375 Total reward: -0.29361037066853635 Training loss: 0.0015\n",
      "Episode: 376 Total reward: -0.26288468186217145 Training loss: 0.0008\n",
      "Episode: 377 Total reward: -0.24356369171363318 Training loss: 0.0011\n",
      "Episode: 378 Total reward: -0.2713300046333357 Training loss: 0.0007\n",
      "Episode: 379 Total reward: -0.24432030061214127 Training loss: 0.0014\n",
      "Episode: 380 Total reward: -0.2564849406845466 Training loss: 0.0007\n",
      "Episode: 381 Total reward: -0.22821047553436793 Training loss: 0.0010\n",
      "Episode: 382 Total reward: -0.2569642289198985 Training loss: 0.0011\n",
      "Episode: 383 Total reward: -0.27295652931312353 Training loss: 0.0009\n",
      "Episode: 384 Total reward: -0.23495973700216277 Training loss: 0.0007\n",
      "Episode: 385 Total reward: -0.28257909172063383 Training loss: 0.0010\n",
      "Episode: 386 Total reward: -0.21824181584520244 Training loss: 0.0009\n",
      "Episode: 387 Total reward: -0.26335570402800007 Training loss: 0.0007\n",
      "Episode: 388 Total reward: -0.25619800148316085 Training loss: 0.0006\n",
      "Episode: 389 Total reward: -0.28230576630352056 Training loss: 0.0008\n",
      "Episode: 390 Total reward: -0.22460316401723832 Training loss: 0.0011\n",
      "Episode: 391 Total reward: -0.26915972364824364 Training loss: 0.0008\n",
      "Episode: 392 Total reward: -0.24012604753702466 Training loss: 0.0007\n",
      "Episode: 393 Total reward: -0.25329682423546684 Training loss: 0.0010\n",
      "Episode: 394 Total reward: -0.23699652528882778 Training loss: 0.0010\n",
      "Episode: 395 Total reward: -0.24531045058469622 Training loss: 0.0009\n",
      "Episode: 396 Total reward: -0.2509070122092181 Training loss: 0.0011\n",
      "Episode: 397 Total reward: -0.26416927459752704 Training loss: 0.0009\n",
      "Episode: 398 Total reward: -0.26688408761640864 Training loss: 0.0011\n",
      "Episode: 399 Total reward: -0.27182080753973326 Training loss: 0.0006\n",
      "Episode: 400 Total reward: -0.25622004906917395 Training loss: 0.0010\n",
      "Episode: 401 Total reward: -0.26618259525896104 Training loss: 0.0004\n",
      "Episode: 402 Total reward: -0.2615218514924347 Training loss: 0.0008\n",
      "Episode: 403 Total reward: -0.2815212526971431 Training loss: 0.0006\n",
      "Episode: 404 Total reward: -0.2531457145064476 Training loss: 0.0007\n",
      "Episode: 405 Total reward: -0.2593128182335694 Training loss: 0.0010\n",
      "Episode: 406 Total reward: -0.26757351138692076 Training loss: 0.0009\n",
      "Episode: 407 Total reward: -0.2681085193426364 Training loss: 0.0007\n",
      "Episode: 408 Total reward: -0.2622221129917845 Training loss: 0.0009\n",
      "Episode: 409 Total reward: -0.25914980103976987 Training loss: 0.0006\n",
      "Episode: 410 Total reward: -0.2489232049544383 Training loss: 0.0010\n",
      "Episode: 411 Total reward: -0.2853224307486124 Training loss: 0.0010\n",
      "Episode: 412 Total reward: -0.2583151951080788 Training loss: 0.0008\n",
      "Episode: 413 Total reward: -0.24165993437870475 Training loss: 0.0009\n",
      "Episode: 414 Total reward: -0.21952526279554754 Training loss: 0.0009\n",
      "Episode: 415 Total reward: -0.3426762181576966 Training loss: 0.0008\n",
      "Episode: 416 Total reward: -0.3156582044501088 Training loss: 0.0009\n",
      "Episode: 417 Total reward: -0.26015627211170717 Training loss: 0.0009\n",
      "Episode: 418 Total reward: -0.27709637997774905 Training loss: 0.0008\n",
      "Episode: 419 Total reward: -0.24850567113327793 Training loss: 0.0009\n",
      "Episode: 420 Total reward: -0.27260293894054166 Training loss: 0.0008\n",
      "Episode: 421 Total reward: -0.26939970653997897 Training loss: 0.0008\n",
      "Episode: 422 Total reward: -0.3079818109455324 Training loss: 0.0005\n",
      "Episode: 423 Total reward: -0.2766693473569737 Training loss: 0.0006\n",
      "Episode: 424 Total reward: -0.3029581786363811 Training loss: 0.0004\n",
      "Episode: 425 Total reward: -0.27931783433242374 Training loss: 0.0008\n",
      "Episode: 426 Total reward: -0.29347233638333514 Training loss: 0.0005\n",
      "Episode: 427 Total reward: -0.3208765172794843 Training loss: 0.0003\n",
      "Episode: 428 Total reward: -0.331322017424093 Training loss: 0.0004\n",
      "Episode: 429 Total reward: -0.3159232154464636 Training loss: 0.0008\n",
      "Episode: 430 Total reward: -0.3017055454375347 Training loss: 0.0007\n",
      "Episode: 431 Total reward: -0.27904694183424417 Training loss: 0.0007\n",
      "Episode: 432 Total reward: -0.2780871140292882 Training loss: 0.0004\n",
      "Episode: 433 Total reward: -0.2814276108997768 Training loss: 0.0005\n",
      "Episode: 434 Total reward: -0.30772528679940964 Training loss: 0.0005\n",
      "Episode: 435 Total reward: -0.2719308825166263 Training loss: 0.0006\n",
      "Episode: 436 Total reward: -0.34949683788652325 Training loss: 0.0010\n",
      "Episode: 437 Total reward: -0.3211385638066094 Training loss: 0.0005\n",
      "Episode: 438 Total reward: -0.26990135624660955 Training loss: 0.0009\n",
      "Episode: 439 Total reward: -0.28744477445034194 Training loss: 0.0007\n",
      "Episode: 440 Total reward: -0.30209837866900624 Training loss: 0.0006\n",
      "Episode: 441 Total reward: -0.2859077945274877 Training loss: 0.0005\n",
      "Episode: 442 Total reward: -0.3080102995436726 Training loss: 0.0004\n",
      "Episode: 443 Total reward: -0.2939384557416323 Training loss: 0.0005\n",
      "Episode: 444 Total reward: -0.3122668595241617 Training loss: 0.0005\n",
      "Episode: 445 Total reward: -0.28183130910768767 Training loss: 0.0002\n",
      "Episode: 446 Total reward: -0.23631370605426164 Training loss: 0.0006\n",
      "Episode: 447 Total reward: -0.28454146540381575 Training loss: 0.0003\n",
      "Episode: 448 Total reward: -0.2671695347947978 Training loss: 0.0008\n",
      "Episode: 449 Total reward: -0.3133302229744685 Training loss: 0.0006\n",
      "Episode: 450 Total reward: -0.26420278044362555 Training loss: 0.0006\n",
      "Episode: 451 Total reward: -0.29770309186554816 Training loss: 0.0004\n",
      "Episode: 452 Total reward: -0.21460948424685744 Training loss: 0.0001\n",
      "Episode: 453 Total reward: -0.2607849175803617 Training loss: 0.0004\n",
      "Episode: 454 Total reward: -0.26256641401138864 Training loss: 0.0004\n",
      "Episode: 455 Total reward: -0.27130690277385316 Training loss: 0.0009\n",
      "Episode: 456 Total reward: -0.2508193330173022 Training loss: 0.0006\n",
      "Episode: 457 Total reward: -0.2615825558246817 Training loss: 0.0008\n",
      "Episode: 458 Total reward: -0.2545716481967447 Training loss: 0.0005\n",
      "Episode: 459 Total reward: -0.3151472741774313 Training loss: 0.0007\n",
      "Episode: 460 Total reward: -0.2971578782245275 Training loss: 0.0005\n",
      "Episode: 461 Total reward: -0.2748480471684121 Training loss: 0.0005\n",
      "Episode: 462 Total reward: -0.3124898878521435 Training loss: 0.0005\n",
      "Episode: 463 Total reward: -0.28888036351328017 Training loss: 0.0005\n",
      "Episode: 464 Total reward: -0.3015986641616291 Training loss: 0.0007\n",
      "Episode: 465 Total reward: -0.3109715521023069 Training loss: 0.0005\n",
      "Episode: 466 Total reward: -0.2856414868531314 Training loss: 0.0003\n",
      "Episode: 467 Total reward: -0.2945199367119747 Training loss: 0.0003\n",
      "Episode: 468 Total reward: -0.2839056655010226 Training loss: 0.0004\n",
      "Episode: 469 Total reward: -0.3269367451570828 Training loss: 0.0003\n",
      "Episode: 470 Total reward: -0.2508724795386582 Training loss: 0.0004\n",
      "Episode: 471 Total reward: -0.2895665803440425 Training loss: 0.0004\n",
      "Episode: 472 Total reward: -0.28521734225757706 Training loss: 0.0004\n",
      "Episode: 473 Total reward: -0.28111346747762833 Training loss: 0.0005\n",
      "Episode: 474 Total reward: -0.288464137278631 Training loss: -0.0002\n",
      "Episode: 475 Total reward: -0.2942685310864277 Training loss: 0.0005\n",
      "Episode: 476 Total reward: -0.3052036244846066 Training loss: 0.0003\n",
      "Episode: 477 Total reward: -0.2592826086719403 Training loss: 0.0005\n",
      "Episode: 478 Total reward: -0.2844669668153129 Training loss: 0.0002\n",
      "Episode: 479 Total reward: -0.25845612314261973 Training loss: 0.0003\n",
      "Episode: 480 Total reward: -0.3085900552346416 Training loss: 0.0004\n",
      "Episode: 481 Total reward: -0.30192162694312835 Training loss: 0.0005\n",
      "Episode: 482 Total reward: -0.2909233976218251 Training loss: 0.0003\n",
      "Episode: 483 Total reward: -0.2577989320436097 Training loss: 0.0005\n",
      "Episode: 484 Total reward: -0.293107236222604 Training loss: 0.0003\n",
      "Episode: 485 Total reward: -0.33354536792480155 Training loss: 0.0004\n",
      "Episode: 486 Total reward: -0.29787865714122397 Training loss: 0.0005\n",
      "Episode: 487 Total reward: -0.2847074817555602 Training loss: 0.0004\n",
      "Episode: 488 Total reward: -0.2822634135821552 Training loss: 0.0004\n",
      "Episode: 489 Total reward: -0.3228985384696129 Training loss: 0.0001\n",
      "Episode: 490 Total reward: -0.28053709095991425 Training loss: 0.0003\n",
      "Episode: 491 Total reward: -0.29590019723872435 Training loss: 0.0001\n",
      "Episode: 492 Total reward: -0.28221047283564016 Training loss: 0.0003\n",
      "Episode: 493 Total reward: -0.28398471834849803 Training loss: 0.0001\n",
      "Episode: 494 Total reward: -0.32747702261131584 Training loss: 0.0002\n",
      "Episode: 495 Total reward: -0.28665472828763117 Training loss: 0.0002\n",
      "Episode: 496 Total reward: -0.32745564763173574 Training loss: 0.0003\n",
      "Episode: 497 Total reward: -0.25532884056940824 Training loss: 0.0002\n",
      "Episode: 498 Total reward: -0.2737713306650556 Training loss: 0.0001\n",
      "Episode: 499 Total reward: -0.2869787870548433 Training loss: 0.0004\n"
     ]
    }
   ],
   "source": [
    "# Now train with experiences\n",
    "#saver = tf.train.Saver()\n",
    "rewards_list = []\n",
    "step = 0\n",
    "opt_q = optim.Adam(q_network.parameters(), learning_rate/5.0)\n",
    "opt_policy = optim.Adam(policy_network.parameters(), learning_rate)\n",
    "\n",
    "outputs = deque(maxlen=10000)\n",
    "\n",
    "count_stop = 0\n",
    "for ep in range(1, train_episodes):\n",
    "    total_reward = 0\n",
    "    # Start new episode\n",
    "    state = env.reset()\n",
    "            \n",
    "    for t in range(max_steps):\n",
    "        action = policy_network(Variable(torch.FloatTensor(state))).data.numpy()\n",
    "        epsilon = max(explore_stop, explore_start*(50.0 - ep)/50.0)\n",
    "        if np.random.rand() < explore_start:\n",
    "            action += 0.2*np.random.rand()\n",
    "        action = np.clip(action, -1, 1)\n",
    "            \n",
    "        result = np.hstack((state, action))\n",
    "        outputs.append(result)\n",
    "\n",
    "        # Take action, get new state and reward\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        total_reward += reward\n",
    "        # Add experience to memory\n",
    "        memory.add((state, action, reward, next_state, done))\n",
    "        \n",
    "        state = next_state\n",
    "\n",
    "        if len(memory.buffer) >= batch_size:\n",
    "            # Sample mini-batch from memory\n",
    "            batch = memory.sample(batch_size)\n",
    "            states = np.array([each[0] for each in batch])\n",
    "            ### ポイント！！！\n",
    "            # actionはスカラーなのでベクトルにする\n",
    "            # actionsはベクトルでなく、statesと同じ行列\n",
    "            actions = np.array([each[1] for each in batch])\n",
    "            ### ポイント終わり\n",
    "            rewards = np.array([[each[2]] for each in batch])\n",
    "            next_states = np.array([each[3] for each in batch])\n",
    "            dones = np.array([[each[4]] for each in batch])\n",
    "\n",
    "            # Train network\n",
    "            #non_final_mask = torch.tensor(tuple(map(lambda s: s==False, dones)), dtype=torch.uint8)\n",
    "            # 終端状態のQ値はその後の報酬が存在しないためゼロとする\n",
    "            #target_maxQs = torch.zeros(batch_size)\n",
    "            #target_maxQs[non_final_mask] = q_network(Variable(torch.FloatTensor(next_states)[non_final_mask])).max(1)[0].detach()\n",
    "\n",
    "            #tutorial way\n",
    "            next_actions = policy_network(Variable(torch.FloatTensor(next_states))).detach()\n",
    "            next_Qs = q_network(torch.cat([torch.FloatTensor(next_states), next_actions], -1)).detach().numpy()\n",
    "            targets = (torch.FloatTensor(rewards) + gamma * torch.FloatTensor(next_Qs*(1-dones)))\n",
    "\n",
    "            current_q_values = q_network(torch.cat([torch.FloatTensor(states), torch.FloatTensor(actions)], -1))\n",
    "\n",
    "            critic_loss = torch.nn.SmoothL1Loss()(current_q_values, targets)\n",
    "            # backpropagation of loss to NN\n",
    "            # 勾配を初期化\n",
    "            opt_q.zero_grad()\n",
    "            critic_loss.backward()\n",
    "            opt_q.step()\n",
    "\n",
    "            #print(loss)\n",
    "\n",
    "            actor_loss = -q_network(torch.cat([torch.FloatTensor(states), policy_network(Variable(torch.FloatTensor(states)))], -1)).mean()\n",
    "            opt_policy.zero_grad()\n",
    "            actor_loss.backward()\n",
    "            opt_policy.step()\n",
    "\n",
    "            #print(loss)\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "    # the episode ends so no next state\n",
    "    print('Episode: {}'.format(ep),\n",
    "          'Total reward: {}'.format(total_reward),\n",
    "          'Training loss: {:.4f}'.format(actor_loss.data.numpy()))\n",
    "    rewards_list.append((ep, total_reward))\n",
    "df = pd.DataFrame(outputs)\n",
    "df.to_csv('result.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_Qs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_network(torch.cat([torch.FloatTensor(states), policy_network(Variable(torch.FloatTensor(states)))], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.buffer.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
